{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b968cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import EMNIST\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9260953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"crawford/emnist\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89695fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\scanu\\\\.cache\\\\kagglehub\\\\datasets\\\\crawford\\\\emnist\\\\versions\\\\3'\n",
    "\n",
    "dataset_file_train = \"/emnist-letters-train.csv\"\n",
    "dataset_file_test = \"/emnist-letters-test.csv\"\n",
    "\n",
    "train = pd.read_csv(path + dataset_file_train, delimiter=',')\n",
    "test = pd.read_csv(path + dataset_file_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a362e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train.iloc[:,0].values)\n",
    "x_train = np.array(train.iloc[:,1:].values)\n",
    "\n",
    "y_test = np.array(test.iloc[:,0].values)\n",
    "x_test = np.array(test.iloc[:,1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fdfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88799, 28, 28)\n",
      "(256, 3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "n_data = len(x_train)\n",
    "height = 28\n",
    "resizer = transforms.Resize((224,224),interpolation=transforms.InterpolationMode.BICUBIC)\n",
    "\n",
    "print(x_train.reshape(n_data,height,height).shape)\n",
    "rgb_batch = np.repeat(x_train.reshape(n_data,height,height), 3, axis = 0).reshape(n_data,3,height,height)[0:256]\n",
    "print(rgb_batch.shape)\n",
    "\n",
    "train_dataloader = DataLoader( [[rgb_batch[i], y_train[i]] for i in range(len(rgb_batch))], batch_size=32, shuffle=False)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b665fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello Transformer\n",
    "class TextRecognitionModel(nn.Module):\n",
    "    def __init__(self, num_classes=27):  # 26 lettere + background\n",
    "        super(TextRecognitionModel, self).__init__()\n",
    "        self.backbone = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        self.backbone.head = nn.Identity()  # Rimuoviamo la testa di classificazione\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=768, nhead=2), num_layers=1\n",
    "        )\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = features.unsqueeze(0)  # Adatta la dimensione per il decoder\n",
    "        decoded = self.decoder(features, features)\n",
    "        output = self.fc(decoded.squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c92c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Batch, Loss: 3.5333\n",
      "This Batch, Loss: 8.5697\n",
      "This Batch, Loss: 5.4542\n",
      "This Batch, Loss: 8.4695\n",
      "This Batch, Loss: 8.9610\n",
      "This Batch, Loss: 8.4569\n"
     ]
    }
   ],
   "source": [
    "# Istanziamento del modello\n",
    "model = TextRecognitionModel(num_classes=27)\n",
    "\n",
    "# Definizione della funzione di perdita e ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Addestramento del modello\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_dataloader:\n",
    "        images = resizer(images).float()\n",
    "#         images = images.unsqueeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs,1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"This Batch, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Addestramento completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ff17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred = torch.max(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b864f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    print(pred[i], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62727bb5",
   "metadata": {},
   "source": [
    "## Attempt with Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if availability else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12023256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Istanziamento del modello\n",
    "model = TextRecognitionModel(num_classes=27).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e632d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione della funzione di perdita e ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Addestramento del modello\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_dataloader:\n",
    "        images = resizer(images).float().to(device)\n",
    "        labels = labels.to(device)\n",
    "#         images = images.unsqueeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"This Batch, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\", end = \"\\n\")\n",
    "\n",
    "print(\"Addestramento completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c60301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
